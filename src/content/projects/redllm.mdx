---
title: RedLLM
id: redllm
year: 2024
domain: [ "ai", "security" ]
status: "active"
featured: true
summary: "Adversarial red-team eval harness for LLMs. Automated jailbreak testing, toxicity probes, and hallucination metrics.<ul><li>60k prompt dataset across 12 attack categories</li><li>240 GPU-hours of fine-tuning and eval</li><li>Judge ensemble (GPT-4 + Claude + Llama Guard)</li><li>CSV/JSON export for compliance reports</li></ul>"
metrics: { gpu_hours: 240, dataset_size: "60k prompts" }
artifacts:
  diagram: "/artifacts/redllm/pipeline.png"
  readme: "https://github.com/you/redllm#readme"
images:
  - "/artifacts/redllm/results.jpg"
  - "/artifacts/redllm/dashboard.jpg"
related: [ "himorogi" ]
---

Adversarial red-team eval harness for LLMs. Automated jailbreak testing, toxicity probes, and hallucination metrics.

- 60k prompt dataset across 12 attack categories
- 240 GPU-hours of fine-tuning and eval
- Judge ensemble (GPT-4 + Claude + Llama Guard)
- CSV/JSON export for compliance reports
